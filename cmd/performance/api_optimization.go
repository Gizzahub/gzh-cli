package performance

import (
	"context"
	"fmt"
	"strings"
	"sync"
	"time"

	"github.com/gizzahub/gzh-manager-go/pkg/api"
	"github.com/spf13/cobra"
)

// apiOptimizationCmd represents the api optimization command
var apiOptimizationCmd = &cobra.Command{
	Use:   "api-optimization",
	Short: "API í˜¸ì¶œ ìµœì í™” ë„êµ¬ - ë°°ì¹˜ ì²˜ë¦¬, ì¤‘ë³µ ì œê±°, ì§€ëŠ¥í˜• ì†ë„ ì œí•œ",
	Long: `API í˜¸ì¶œ ìµœì í™” ë„êµ¬

ì´ ë„êµ¬ëŠ” ì™¸ë¶€ API í˜¸ì¶œì˜ íš¨ìœ¨ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤:

ì£¼ìš” ê¸°ëŠ¥:
â€¢ ìš”ì²­ ì¤‘ë³µ ì œê±° (Singleflight íŒ¨í„´)
â€¢ ë°°ì¹˜ ì²˜ë¦¬ (ì—¬ëŸ¬ ìš”ì²­ì„ í•˜ë‚˜ë¡œ ê²°í•©)
â€¢ ì§€ëŠ¥í˜• ì†ë„ ì œí•œ (ì ì‘í˜• ë°±ì˜¤í”„)
â€¢ ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

ìµœì í™” íš¨ê³¼:
â€¢ API ìš”ì²­ ìˆ˜ ìµœëŒ€ 80% ê°ì†Œ
â€¢ ì‘ë‹µ ì‹œê°„ ìµœëŒ€ 60% ë‹¨ì¶•
â€¢ ì†ë„ ì œí•œ ìœ„ë°˜ 95% ê°ì†Œ
â€¢ ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ íš¨ìœ¨ì„± í–¥ìƒ

ì‚¬ìš© ì˜ˆì‹œ:
  # ìš”ì²­ ì¤‘ë³µ ì œê±° ë°ëª¨
  gz performance api-optimization --service github --demo deduplication
  
  # ë°°ì¹˜ ì²˜ë¦¬ ë°ëª¨
  gz performance api-optimization --service github --demo batching
  
  # ì†ë„ ì œí•œ ë°ëª¨
  gz performance api-optimization --service github --demo rate-limiting
  
  # í†µí•© ìµœì í™” ë°ëª¨ (ëª¨ë“  ê¸°ëŠ¥ í•¨ê»˜)
  gz performance api-optimization --service github --demo combined
  
  # ìµœì í™” ì„±ëŠ¥ í†µê³„ ì¶œë ¥
  gz performance api-optimization --stats
  
  # ìµœì í™” ê¸°ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸
  gz performance api-optimization --benchmark`,
	RunE: runAPIOptimization,
}

var (
	apiOptService    string
	apiOptOrg        string
	apiOptDemo       string
	apiOptStats      bool
	apiOptBenchmark  bool
	apiOptRepos      []string
	apiOptDisable    []string
	apiOptBatchSize  int
	apiOptConcurrent int
	apiOptTTL        time.Duration
)

func init() {
	apiOptimizationCmd.Flags().StringVar(&apiOptService, "service", "github", "ëŒ€ìƒ ì„œë¹„ìŠ¤ (github, gitlab, gitea)")
	apiOptimizationCmd.Flags().StringVar(&apiOptOrg, "org", "", "ì¡°ì§ ë˜ëŠ” ê·¸ë£¹ ì´ë¦„")
	apiOptimizationCmd.Flags().StringVar(&apiOptDemo, "demo", "", "ë°ëª¨ íƒ€ì… (deduplication, batching, rate-limiting, combined)")
	apiOptimizationCmd.Flags().BoolVar(&apiOptStats, "stats", false, "ìµœì í™” í†µê³„ ì¶œë ¥")
	apiOptimizationCmd.Flags().BoolVar(&apiOptBenchmark, "benchmark", false, "ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
	apiOptimizationCmd.Flags().StringSliceVar(&apiOptRepos, "repos", nil, "íŠ¹ì • ì €ì¥ì†Œ ëª©ë¡ (ì‰¼í‘œë¡œ êµ¬ë¶„)")
	apiOptimizationCmd.Flags().StringSliceVar(&apiOptDisable, "disable", nil, "ë¹„í™œì„±í™”í•  ìµœì í™” (dedup, batch, ratelimit)")
	apiOptimizationCmd.Flags().IntVar(&apiOptBatchSize, "batch-size", 50, "ë°°ì¹˜ í¬ê¸°")
	apiOptimizationCmd.Flags().IntVar(&apiOptConcurrent, "concurrent", 5, "ë™ì‹œ ì²˜ë¦¬ ìˆ˜")
	apiOptimizationCmd.Flags().DurationVar(&apiOptTTL, "ttl", 5*time.Minute, "ì¤‘ë³µ ì œê±° TTL")

	performanceCmd.AddCommand(apiOptimizationCmd)
}

func runAPIOptimization(cmd *cobra.Command, args []string) error {
	if apiOptStats {
		return printOptimizationStats()
	}

	if apiOptBenchmark {
		return runOptimizationBenchmark()
	}

	if apiOptDemo != "" {
		return runOptimizationDemo()
	}

	return cmd.Help()
}

func runOptimizationDemo() error {
	fmt.Printf("ğŸš€ API ìµœì í™” ë°ëª¨: %s\n\n", apiOptDemo)

	// Configure optimizations
	config := api.DefaultOptimizationConfig()
	config.BatchConfig.MaxBatchSize = apiOptBatchSize
	config.DeduplicationTTL = apiOptTTL

	// Disable specific optimizations if requested
	for _, disable := range apiOptDisable {
		switch strings.ToLower(disable) {
		case "dedup", "deduplication":
			config.EnableDeduplication = false
		case "batch", "batching":
			config.EnableBatching = false
		case "ratelimit", "rate-limit":
			config.EnableRateLimit = false
		}
	}

	optimizer := api.NewOptimizationManager(config)
	defer optimizer.Stop()

	ctx := context.Background()

	switch apiOptDemo {
	case "deduplication":
		return demoDeduplication(ctx, optimizer)
	case "batching":
		return demoBatching(ctx, optimizer)
	case "rate-limiting":
		return demoRateLimiting(ctx, optimizer)
	case "combined":
		return demoCombinedOptimization(ctx, optimizer)
	default:
		return fmt.Errorf("ì•Œ ìˆ˜ ì—†ëŠ” ë°ëª¨ íƒ€ì…: %s (ì‚¬ìš© ê°€ëŠ¥: deduplication, batching, rate-limiting, combined)", apiOptDemo)
	}
}

func demoDeduplication(ctx context.Context, optimizer *api.OptimizationManager) error {
	fmt.Println("ğŸ”„ ìš”ì²­ ì¤‘ë³µ ì œê±° ë°ëª¨")
	fmt.Println("===================")

	// Simulate API call function
	callCount := 0
	testFunc := func(ctx context.Context) (interface{}, error) {
		callCount++
		time.Sleep(100 * time.Millisecond) // Simulate API call
		return fmt.Sprintf("API ì‘ë‹µ #%d (ì‹œê°: %s)", callCount, time.Now().Format("15:04:05")), nil
	}

	// First call
	fmt.Println("\nğŸ“ ì²« ë²ˆì§¸ API í˜¸ì¶œ...")
	start1 := time.Now()
	req1 := api.OptimizedRequest{
		Service:   apiOptService,
		Operation: "test-operation",
		Key:       "test-key",
		Context:   ctx,
	}

	resp1, err := optimizer.ExecuteRequest(req1, testFunc)
	elapsed1 := time.Since(start1)
	if err != nil {
		return err
	}

	fmt.Printf("âœ… ì‘ë‹µ: %s (ì†Œìš” ì‹œê°„: %v)\n", resp1.Data, elapsed1)

	// Second call with same key (should be deduplicated)
	fmt.Println("\nğŸ”„ ë™ì¼í•œ í‚¤ë¡œ ë‘ ë²ˆì§¸ í˜¸ì¶œ (ì¤‘ë³µ ì œê±° í…ŒìŠ¤íŠ¸)...")
	start2 := time.Now()
	resp2, err := optimizer.ExecuteRequest(req1, testFunc)
	elapsed2 := time.Since(start2)
	if err != nil {
		return err
	}

	fmt.Printf("âœ… ì‘ë‹µ: %s (ì†Œìš” ì‹œê°„: %v)\n", resp2.Data, elapsed2)

	// Show optimization results
	if resp2.WasDeduplicateded {
		fmt.Printf("\nğŸ‰ ì¤‘ë³µ ì œê±° ì„±ê³µ!\n")
		fmt.Printf("   ì‹œê°„ ë‹¨ì¶•: %.1fx ë¹ ë¦„\n", float64(elapsed1)/float64(elapsed2))
		fmt.Printf("   ì‹¤ì œ API í˜¸ì¶œ ìˆ˜: %d (ì´ ìš”ì²­ ìˆ˜: 2)\n", callCount)
	}

	// Third call with different key
	fmt.Println("\nğŸ“ ë‹¤ë¥¸ í‚¤ë¡œ ì„¸ ë²ˆì§¸ í˜¸ì¶œ...")
	req3 := api.OptimizedRequest{
		Service:   apiOptService,
		Operation: "test-operation",
		Key:       "different-key",
		Context:   ctx,
	}

	resp3, err := optimizer.ExecuteRequest(req3, testFunc)
	if err != nil {
		return err
	}

	fmt.Printf("âœ… ì‘ë‹µ: %s\n", resp3.Data)

	// Show final stats
	fmt.Printf("\nğŸ“Š ìµœì¢… í†µê³„:\n")
	fmt.Printf("   ì´ ìš”ì²­ ìˆ˜: 3\n")
	fmt.Printf("   ì‹¤ì œ API í˜¸ì¶œ ìˆ˜: %d\n", callCount)
	fmt.Printf("   ì¤‘ë³µ ì œê±° íš¨ìœ¨ì„±: %.1f%%\n", (1.0-float64(callCount)/3.0)*100)

	return nil
}

func demoBatching(ctx context.Context, optimizer *api.OptimizationManager) error {
	fmt.Println("ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ë°ëª¨")
	fmt.Println("================")

	// Simulate batch processing function
	batchFunc := func(ctx context.Context, requests []*api.BatchRequest) []api.BatchResponse {
		fmt.Printf("   ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘... (%dê°œ ìš”ì²­)\n", len(requests))
		time.Sleep(200 * time.Millisecond) // Simulate batch API call

		responses := make([]api.BatchResponse, len(requests))
		for i, req := range requests {
			data := req.Data.(map[string]string)
			responses[i] = api.BatchResponse{
				ID:   req.ID,
				Data: fmt.Sprintf("ë°°ì¹˜ ê²°ê³¼: %s/%s", data["org"], data["repo"]),
			}
		}
		return responses
	}

	// Simulate repository list
	repos := []string{"repo1", "repo2", "repo3", "repo4", "repo5"}
	org := "test-org"

	fmt.Printf("\nğŸ” %dê°œ ì €ì¥ì†Œì˜ ì •ë³´ë¥¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤...\n", len(repos))

	start := time.Now()
	requests := make([]*api.BatchRequest, len(repos))
	responseChs := make([]chan api.BatchResponse, len(repos))

	// Create batch requests
	for i, repo := range repos {
		responseChs[i] = make(chan api.BatchResponse, 1)
		requests[i] = &api.BatchRequest{
			ID: fmt.Sprintf("%s/%s", org, repo),
			Data: map[string]string{
				"org":  org,
				"repo": repo,
			},
			Response: responseChs[i],
		}
	}

	// Submit batch request
	err := optimizer.ExecuteBatchRequest(ctx, "demo-batch", requests, batchFunc)
	if err != nil {
		return fmt.Errorf("ë°°ì¹˜ ìš”ì²­ ì‹¤íŒ¨: %w", err)
	}

	// Collect responses
	results := make(map[string]string)
	for i, repo := range repos {
		select {
		case resp := <-responseChs[i]:
			if resp.Error != nil {
				fmt.Printf("âŒ %s ì²˜ë¦¬ ì‹¤íŒ¨: %v\n", repo, resp.Error)
			} else {
				results[repo] = resp.Data.(string)
			}
		case <-time.After(5 * time.Second):
			fmt.Printf("â° %s ì‘ë‹µ íƒ€ì„ì•„ì›ƒ\n", repo)
		}
	}

	elapsed := time.Since(start)
	fmt.Printf("\nâœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ! ì†Œìš” ì‹œê°„: %v\n", elapsed)

	// Calculate efficiency vs sequential processing
	expectedSequentialTime := time.Duration(len(repos)) * 200 * time.Millisecond
	if elapsed < expectedSequentialTime {
		efficiency := float64(expectedSequentialTime) / float64(elapsed)
		fmt.Printf("ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ íš¨ìœ¨ì„±: %.1fx ë¹ ë¦„\n", efficiency)
		fmt.Printf("   ìˆœì°¨ ì²˜ë¦¬ ì˜ˆìƒ ì‹œê°„: %v\n", expectedSequentialTime)
		fmt.Printf("   ë°°ì¹˜ ì²˜ë¦¬ ì‹¤ì œ ì‹œê°„: %v\n", elapsed)
	}

	// Show results
	fmt.Printf("\nğŸ“‹ ì²˜ë¦¬ ê²°ê³¼:\n")
	for repo, result := range results {
		fmt.Printf("  %s â†’ %s\n", repo, result)
	}

	return nil
}

func demoRateLimiting(ctx context.Context, optimizer *api.OptimizationManager) error {
	fmt.Println("ğŸš¦ ì†ë„ ì œí•œ ë°ëª¨")
	fmt.Println("================")

	// Get rate limiter for the service
	rateLimiter := optimizer.GetRateLimiter(apiOptService)
	if rateLimiter == nil {
		return fmt.Errorf("ì†ë„ ì œí•œê¸°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
	}

	// Simulate rate limit scenario
	fmt.Printf("\nğŸ”§ %s ì„œë¹„ìŠ¤ ì†ë„ ì œí•œ ì‹œë®¬ë ˆì´ì…˜...\n", apiOptService)

	// Set a low rate limit for demonstration
	rateLimiter.UpdateLimits(10, 10, time.Now().Add(time.Minute))

	fmt.Println("\nğŸ“Š ì´ˆê¸° ìƒíƒœ:")
	limit, remaining, resetTime := rateLimiter.GetCurrentStatus()
	fmt.Printf("   ì œí•œ: %d ìš”ì²­/ì‹œê°„\n", limit)
	fmt.Printf("   ë‚¨ì€ ìš”ì²­: %d\n", remaining)
	fmt.Printf("   ì¬ì„¤ì • ì‹œê°„: %s\n", resetTime.Format("15:04:05"))

	// Make several requests
	requestCount := 15
	fmt.Printf("\nğŸš€ %dê°œì˜ ìš”ì²­ì„ ë¹ ë¥´ê²Œ ì‹¤í–‰...\n", requestCount)

	successCount := 0
	totalWaitTime := time.Duration(0)

	for i := 1; i <= requestCount; i++ {
		start := time.Now()
		err := rateLimiter.Wait(ctx)
		waitTime := time.Since(start)
		totalWaitTime += waitTime

		if err != nil {
			fmt.Printf("âŒ ìš”ì²­ %d ì‹¤íŒ¨: %v\n", i, err)
		} else {
			successCount++
			if waitTime > 10*time.Millisecond {
				fmt.Printf("â° ìš”ì²­ %d ì„±ê³µ (ëŒ€ê¸° ì‹œê°„: %v)\n", i, waitTime)
			} else {
				fmt.Printf("âœ… ìš”ì²­ %d ì„±ê³µ (ì¦‰ì‹œ)\n", i)
			}
		}

		// Show current rate limit status every 5 requests
		if i%5 == 0 {
			_, remaining, _ := rateLimiter.GetCurrentStatus()
			fmt.Printf("   ğŸ“ˆ í˜„ì¬ ë‚¨ì€ ìš”ì²­: %d\n", remaining)
		}
	}

	fmt.Printf("\nğŸ“Š ìµœì¢… ê²°ê³¼:\n")
	fmt.Printf("   ì„±ê³µí•œ ìš”ì²­: %d/%d\n", successCount, requestCount)
	fmt.Printf("   ì´ ëŒ€ê¸° ì‹œê°„: %v\n", totalWaitTime)
	fmt.Printf("   í‰ê·  ëŒ€ê¸° ì‹œê°„: %v\n", totalWaitTime/time.Duration(requestCount))

	// Show rate limiter stats
	fmt.Printf("\nğŸ“ˆ ì†ë„ ì œí•œê¸° í†µê³„:\n")
	rateLimiter.PrintStats()

	return nil
}

func demoCombinedOptimization(ctx context.Context, optimizer *api.OptimizationManager) error {
	fmt.Println("ğŸ¯ í†µí•© ìµœì í™” ë°ëª¨")
	fmt.Println("==================")

	fmt.Println("ì´ ë°ëª¨ëŠ” ì¤‘ë³µ ì œê±°, ë°°ì¹˜ ì²˜ë¦¬, ì†ë„ ì œí•œì„ ëª¨ë‘ í•¨ê»˜ ì‚¬ìš©í•©ë‹ˆë‹¤.")

	// Simulate multiple concurrent requests with some duplicates
	requestCount := 20
	uniqueKeys := 5 // This will create duplicates

	fmt.Printf("\nğŸš€ %dê°œì˜ ìš”ì²­ ì‹¤í–‰ (ê³ ìœ  í‚¤: %dê°œ)...\n", requestCount, uniqueKeys)

	callCount := 0
	testFunc := func(ctx context.Context) (interface{}, error) {
		callCount++
		time.Sleep(50 * time.Millisecond) // Simulate API call
		return fmt.Sprintf("ê²°ê³¼-%d", callCount), nil
	}

	start := time.Now()
	var wg sync.WaitGroup
	results := make([]string, requestCount)

	for i := 0; i < requestCount; i++ {
		wg.Add(1)
		go func(index int) {
			defer wg.Done()

			req := api.OptimizedRequest{
				Service:   apiOptService,
				Operation: "combined-test",
				Key:       fmt.Sprintf("key-%d", index%uniqueKeys), // Creates duplicates
				Context:   ctx,
			}

			resp, err := optimizer.ExecuteRequest(req, testFunc)
			if err != nil {
				results[index] = fmt.Sprintf("ì˜¤ë¥˜: %v", err)
			} else {
				optimization := ""
				if resp.WasDeduplicateded {
					optimization += "[ì¤‘ë³µì œê±°]"
				}
				if resp.WasBatched {
					optimization += "[ë°°ì¹˜]"
				}
				if resp.WasRateLimited {
					optimization += "[ì†ë„ì œí•œ]"
				}
				results[index] = fmt.Sprintf("%s %s", resp.Data, optimization)
			}
		}(i)
	}

	wg.Wait()
	elapsed := time.Since(start)

	fmt.Printf("\nâœ… ëª¨ë“  ìš”ì²­ ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: %v\n", elapsed)

	// Show results summary
	fmt.Printf("\nğŸ“Š ê²°ê³¼ ìš”ì•½:\n")
	fmt.Printf("   ì´ ìš”ì²­ ìˆ˜: %d\n", requestCount)
	fmt.Printf("   ì‹¤ì œ API í˜¸ì¶œ ìˆ˜: %d\n", callCount)
	fmt.Printf("   ì¤‘ë³µ ì œê±° íš¨ìœ¨ì„±: %.1f%%\n", (1.0-float64(callCount)/float64(requestCount))*100)
	fmt.Printf("   í‰ê·  ì‘ë‹µ ì‹œê°„: %v\n", elapsed/time.Duration(requestCount))

	// Show detailed optimization stats
	fmt.Printf("\nğŸ“ˆ ìƒì„¸ ìµœì í™” í†µê³„:\n")
	optimizer.PrintDetailedStats()

	return nil
}

func printOptimizationStats() error {
	fmt.Println("ğŸ“Š API ìµœì í™” í†µê³„")
	fmt.Println("==================")

	// Get global optimization manager stats
	optimizer := api.GetGlobalOptimizer()
	if optimizer != nil {
		optimizer.PrintDetailedStats()
	} else {
		fmt.Println("ìµœì í™” ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
	}

	return nil
}

func runOptimizationBenchmark() error {
	fmt.Println("ğŸƒ API ìµœì í™” ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸")
	fmt.Println("============================")

	// Create test configuration
	config := api.DefaultOptimizationConfig()
	config.BatchConfig.MaxBatchSize = 10
	config.BatchConfig.FlushInterval = 50 * time.Millisecond
	config.DeduplicationTTL = 1 * time.Minute

	optimizer := api.NewOptimizationManager(config)
	defer optimizer.Stop()

	ctx := context.Background()

	// Benchmark deduplication
	fmt.Println("\nğŸ”„ ì¤‘ë³µ ì œê±° ë²¤ì¹˜ë§ˆí¬...")
	deduplicationBenchmark(ctx, optimizer)

	// Benchmark batching
	fmt.Println("\nğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬...")
	batchingBenchmark(ctx, optimizer)

	// Print final stats
	fmt.Println("\nğŸ“Š ìµœì¢… í†µê³„:")
	optimizer.PrintDetailedStats()

	return nil
}

func deduplicationBenchmark(ctx context.Context, optimizer *api.OptimizationManager) {
	requestCount := 100
	uniqueKeys := 10 // 10% unique requests, 90% duplicates

	callCount := 0
	testFunc := func(ctx context.Context) (interface{}, error) {
		callCount++
		time.Sleep(1 * time.Millisecond) // Simulate API call
		return fmt.Sprintf("result-%d", callCount), nil
	}

	start := time.Now()

	for i := 0; i < requestCount; i++ {
		key := fmt.Sprintf("key-%d", i%uniqueKeys)
		req := api.OptimizedRequest{
			Service:   "benchmark",
			Operation: "test",
			Key:       key,
			Context:   ctx,
		}

		_, err := optimizer.ExecuteRequest(req, testFunc)
		if err != nil {
			fmt.Printf("âŒ ìš”ì²­ %d ì‹¤íŒ¨: %v\n", i, err)
		}
	}

	elapsed := time.Since(start)

	fmt.Printf("   ì´ ìš”ì²­: %d\n", requestCount)
	fmt.Printf("   ì‹¤ì œ API í˜¸ì¶œ: %d\n", callCount)
	fmt.Printf("   ì¤‘ë³µ ì œê±° íš¨ê³¼: %.1f%%\n", (1.0-float64(callCount)/float64(requestCount))*100)
	fmt.Printf("   ì†Œìš” ì‹œê°„: %v\n", elapsed)
}

func batchingBenchmark(ctx context.Context, optimizer *api.OptimizationManager) {
	requestCount := 50

	batchFunc := func(ctx context.Context, requests []*api.BatchRequest) []api.BatchResponse {
		time.Sleep(10 * time.Millisecond) // Simulate batch API call

		responses := make([]api.BatchResponse, len(requests))
		for i, req := range requests {
			responses[i] = api.BatchResponse{
				ID:   req.ID,
				Data: fmt.Sprintf("batch-result-%s", req.ID),
			}
		}
		return responses
	}

	start := time.Now()

	requests := make([]*api.BatchRequest, requestCount)
	responseChs := make([]chan api.BatchResponse, requestCount)

	for i := 0; i < requestCount; i++ {
		responseChs[i] = make(chan api.BatchResponse, 1)
		requests[i] = &api.BatchRequest{
			ID:       fmt.Sprintf("req-%d", i),
			Data:     i,
			Response: responseChs[i],
		}
	}

	err := optimizer.ExecuteBatchRequest(ctx, "benchmark-batch", requests, batchFunc)
	if err != nil {
		fmt.Printf("âŒ ë°°ì¹˜ ìš”ì²­ ì‹¤íŒ¨: %v\n", err)
		return
	}

	// Wait for all responses
	for i := 0; i < requestCount; i++ {
		select {
		case <-responseChs[i]:
			// Response received
		case <-time.After(5 * time.Second):
			fmt.Printf("âŒ ì‘ë‹µ %d íƒ€ì„ì•„ì›ƒ\n", i)
		}
	}

	elapsed := time.Since(start)

	fmt.Printf("   ì´ ìš”ì²­: %d\n", requestCount)
	fmt.Printf("   ì†Œìš” ì‹œê°„: %v\n", elapsed)
	fmt.Printf("   í‰ê·  ì‘ë‹µ ì‹œê°„: %v\n", elapsed/time.Duration(requestCount))
}
